{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import pickle\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(\"../Data\", download=True)\n",
    "tt = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tp = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "# def label_to_onehot(target, num_classes=100):\n",
    "#     target = torch.unsqueeze(target, 1)\n",
    "#     onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "#     onehot_target.scatter_(1, target, 1)\n",
    "#     return onehot_target\n",
    "\n",
    "# def cross_entropy_for_onehot(pred, target):\n",
    "#     return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    try:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.weight' % m._get_name())\n",
    "    try:\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.bias' % m._get_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100 root_path: .\n",
      "cifar100 data_path: ./../Data\n",
      "cifar100 save_path: ./results/DLG_cifar100\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cifar100'\n",
    "root_path = '.'\n",
    "data_path = os.path.join(root_path, '../Data')\n",
    "save_path = os.path.join(root_path, 'results/DLG_%s'%dataset)\n",
    "\n",
    "lr = 1.0\n",
    "num_dummy = 1\n",
    "Iteration = 300\n",
    "num_exp = 10\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "tt = transforms.Compose([transforms.ToTensor()])\n",
    "tp = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "print(dataset, 'root_path:', root_path)\n",
    "print(dataset, 'data_path:', data_path)\n",
    "print(dataset, 'save_path:', save_path)\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "\n",
    "\n",
    "''' load data '''\n",
    "\n",
    "if dataset == 'cifar100':\n",
    "    shape_img = (32, 32)\n",
    "    num_classes = 100\n",
    "    channel = 3\n",
    "    hidden = 768\n",
    "    dataset = datasets.CIFAR100(data_path, download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(len(dataset)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:13:36] 0 loss = 57.61106491, mse = 1.37180734\n",
      "imidx_list: [0]\n",
      "loss_DLG: 1.3908012306274031e-06\n",
      "mse_DLG: 4.171279942966066e-05\n",
      "gt_label: [19] lab_DLG: 19\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 1|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:14:30] 0 loss = 267.19042969, mse = 128.79145813\n",
      "imidx_list: [0]\n",
      "loss_DLG: 340.7730407714844\n",
      "mse_DLG: 1180934144.0\n",
      "gt_label: [19] lab_DLG: 19\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 2|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:14:35] 0 loss = 58.21468735, mse = 1.59555364\n",
      "imidx_list: [0]\n",
      "loss_DLG: 2.6674988475861028e-06\n",
      "mse_DLG: 3.2109933272295166e-06\n",
      "gt_label: [19] lab_DLG: 19\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 3|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:15:34] 0 loss = 95.12958527, mse = 1.40058219\n",
      "imidx_list: [0]\n",
      "loss_DLG: 1.977718056878075e-06\n",
      "mse_DLG: 2.0923409465467557e-05\n",
      "gt_label: [19] lab_DLG: 19\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 4|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:16:18] 0 loss = 601.78051758, mse = 17.64070320\n",
      "imidx_list: [0]\n",
      "loss_DLG: 1253.29248046875\n",
      "mse_DLG: 2546825216.0\n",
      "gt_label: [19] lab_DLG: 35\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 5|10 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2025-02-09 21:16:20] 0 loss = 68.36886597, mse = 1.37445343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "''' train DLG and iDLG '''\n",
    "for idx_net in range(num_exp):\n",
    "    net = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "    net.apply(weights_init)\n",
    "\n",
    "    print('running %d|%d experiment'%(idx_net, num_exp))##\n",
    "    net = net.to(device)\n",
    "    # idx_shuffle = np.random.permutation(len(dataset))\n",
    "\n",
    "    print('%s, Try to generate %d images' % (\"DLG\", num_dummy))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    imidx_list = []\n",
    "\n",
    "    for imidx in range(num_dummy):\n",
    "        # idx = idx_shuffle[imidx]\n",
    "        idx = imidx\n",
    "        imidx_list.append(idx)\n",
    "        tmp_datum = tt(dataset[idx][0]).float().to(device)\n",
    "        tmp_datum = tmp_datum.view(1, *tmp_datum.size())\n",
    "        tmp_label = torch.Tensor([dataset[idx][1]]).long().to(device)\n",
    "        tmp_label = tmp_label.view(1, )\n",
    "        if imidx == 0:\n",
    "            gt_data = tmp_datum\n",
    "            gt_label = tmp_label\n",
    "        else:\n",
    "            gt_data = torch.cat((gt_data, tmp_datum), dim=0)\n",
    "            gt_label = torch.cat((gt_label, tmp_label), dim=0)\n",
    "\n",
    "\n",
    "    # compute original gradient\n",
    "    out = net(gt_data)\n",
    "    y = criterion(out, gt_label)\n",
    "    dy_dx = torch.autograd.grad(y, net.parameters())\n",
    "    original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "    # generate dummy data and label\n",
    "    dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
    "    dummy_label = torch.randn((gt_data.shape[0], num_classes)).to(device).requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.LBFGS([dummy_data, dummy_label], lr=lr)\n",
    "\n",
    "\n",
    "    history = []\n",
    "    history_iters = []\n",
    "    losses = []\n",
    "    mses = []\n",
    "    train_iters = []\n",
    "\n",
    "    print('lr =', lr)\n",
    "    for iters in range(Iteration):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(dummy_data)\n",
    "\n",
    "            dummy_loss = - torch.mean(torch.sum(torch.softmax(dummy_label, -1) * torch.log(torch.softmax(pred, -1)), dim=-1))\n",
    "            # dummy_loss = criterion(pred, gt_label)\n",
    "\n",
    "\n",
    "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "\n",
    "            grad_diff = 0\n",
    "            for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
    "                grad_diff += ((gx - gy) ** 2).sum()\n",
    "            grad_diff.backward()\n",
    "            return grad_diff\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        current_loss = closure().item()\n",
    "        train_iters.append(iters)\n",
    "        losses.append(current_loss)\n",
    "        mses.append(torch.mean((dummy_data-gt_data)**2).item())\n",
    "\n",
    "\n",
    "        if iters % int(Iteration+1 / 30) == 0:\n",
    "            current_time = str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
    "            print(current_time, iters, 'loss = %.8f, mse = %.8f' %(current_loss, mses[-1]))\n",
    "            history.append([tp(dummy_data[imidx].cpu()) for imidx in range(num_dummy)])\n",
    "            history_iters.append(iters)\n",
    "\n",
    "            for imidx in range(num_dummy):\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.subplot(3, 10, 1)\n",
    "                plt.imshow(tp(gt_data[imidx].cpu()))\n",
    "                for i in range(min(len(history), 29)):\n",
    "                    plt.subplot(3, 10, i + 2)\n",
    "                    plt.imshow(history[i][imidx])\n",
    "                    plt.title('iter=%d' % (history_iters[i]))\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.savefig('%s/DLG_on_%s_%05d.png' % (save_path, imidx_list, imidx_list[imidx]))\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "            if current_loss < 0.000001: # converge\n",
    "                break\n",
    "\n",
    "    loss_DLG = losses\n",
    "    label_DLG = torch.argmax(dummy_label, dim=-1).detach().item()\n",
    "    mse_DLG = mses\n",
    "\n",
    "\n",
    "    print('imidx_list:', imidx_list)\n",
    "    print('loss_DLG:', loss_DLG[-1], )\n",
    "    print('mse_DLG:', mse_DLG[-1])\n",
    "    print('gt_label:', gt_label.detach().cpu().data.numpy(), 'lab_DLG:', label_DLG, )\n",
    "\n",
    "    print('----------------------\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1262153168.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    -------\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
